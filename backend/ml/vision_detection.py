"""
Vision Model Service for Fake Profile Picture Detection
Uses pretrained ResNet50/EfficientNet for binary classification: real vs AI/stock
Returns probability scores (0-1) where 1 = likely fake/AI-generated
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
import PIL.Image as Image
import numpy as np
import logging
from typing import Dict, Any, Optional, Union
import io
import base64
from functools import lru_cache
import time

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FakeProfileDetector:
    """
    Vision model for detecting fake/AI-generated profile pictures
    """
    
    def __init__(self, model_type: str = "resnet50", device: Optional[str] = None):
        """
        Initialize the fake profile detector
        
        Args:
            model_type: Type of model to use ("resnet50" or "efficientnet")
            device: Device to run inference on (auto-detected if None)
        """
        self.model_type = model_type
        self.device = device or self._get_device()
        self.model = None
        self.transforms = None
        self.is_loaded = False
        
        # Load model on initialization
        self._load_model()
        
    def _get_device(self) -> str:
        """Get the best available device"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def _load_model(self):
        """Load the pretrained model and modify for binary classification"""
        try:
            logger.info(f"Loading {self.model_type} model for fake profile detection...")
            
            if self.model_type == "resnet50":
                # Load pretrained ResNet50
                self.model = models.resnet50(pretrained=True)
                # Modify final layer for binary classification
                num_features = self.model.fc.in_features
                self.model.fc = nn.Sequential(
                    nn.Dropout(0.5),
                    nn.Linear(num_features, 256),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(256, 2)  # Binary classification: real vs fake
                )
                
            elif self.model_type == "efficientnet":
                # Load pretrained EfficientNet-B0
                self.model = models.efficientnet_b0(pretrained=True)
                # Modify classifier for binary classification
                num_features = self.model.classifier[1].in_features
                self.model.classifier = nn.Sequential(
                    nn.Dropout(0.5),
                    nn.Linear(num_features, 256),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(256, 2)  # Binary classification: real vs fake
                )
            else:
                raise ValueError(f"Unsupported model type: {self.model_type}")
            
            # Move model to device
            self.model = self.model.to(self.device)
            self.model.eval()
            
            # Set up image transforms
            self.transforms = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]
                )
            ])
            
            # Note: In a real scenario, you would load fine-tuned weights here
            # For now, we'll use the pretrained features with a mock classification head
            logger.info("âš ï¸  Using pretrained features with mock classification head")
            logger.info("ðŸ“ In production, load fine-tuned weights trained on real vs fake images")
            
            self.is_loaded = True
            logger.info(f"âœ… {self.model_type} model loaded successfully on {self.device}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load vision model: {e}")
            self.is_loaded = False
            raise
    
    def _preprocess_image(self, image: Union[Image.Image, np.ndarray, bytes]) -> torch.Tensor:
        """
        Preprocess image for model inference
        
        Args:
            image: PIL Image, numpy array, or bytes
            
        Returns:
            Preprocessed tensor ready for inference
        """
        try:
            # Handle different input types
            if isinstance(image, bytes):
                image = Image.open(io.BytesIO(image))
            elif isinstance(image, np.ndarray):
                image = Image.fromarray(image)
            elif not isinstance(image, Image.Image):
                raise ValueError(f"Unsupported image type: {type(image)}")
            
            # Convert to RGB if needed
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Apply transforms
            tensor = self.transforms(image)
            
            # Add batch dimension
            tensor = tensor.unsqueeze(0)
            
            return tensor.to(self.device)
            
        except Exception as e:
            logger.error(f"Image preprocessing failed: {e}")
            raise
    
    @lru_cache(maxsize=100)
    def _get_mock_features(self, image_hash: str) -> float:
        """
        Generate mock features for demonstration
        In production, this would be replaced with actual model inference
        """
        # Simple hash-based mock that gives consistent results
        hash_val = hash(image_hash) % 1000
        
        # Create some realistic-looking patterns
        if hash_val < 200:  # 20% likely fake
            return 0.7 + (hash_val % 30) / 100  # 0.7-0.99
        elif hash_val < 400:  # 20% moderate suspicion
            return 0.4 + (hash_val % 30) / 100  # 0.4-0.69
        else:  # 60% likely real
            return 0.05 + (hash_val % 35) / 100  # 0.05-0.39
    
    def detect_fake_profile(self, image: Union[Image.Image, np.ndarray, bytes]) -> Dict[str, Any]:
        """
        Detect if a profile picture is fake/AI-generated
        
        Args:
            image: Input image (PIL Image, numpy array, or bytes)
            
        Returns:
            Dictionary with detection results and confidence scores
        """
        if not self.is_loaded:
            return {
                "error": "Model not loaded",
                "is_fake": False,
                "confidence": 0.0,
                "fake_probability": 0.0,
                "real_probability": 1.0,
                "model_status": "not_loaded"
            }
        
        start_time = time.time()
        
        try:
            # Preprocess image
            image_tensor = self._preprocess_image(image)
            
            # For demonstration, we'll use mock inference
            # In production, you would use: outputs = self.model(image_tensor)
            
            # Create a simple hash of the image for consistent mock results
            image_hash = str(hash(image_tensor.cpu().numpy().tobytes()))
            fake_probability = self._get_mock_features(image_hash)
            
            # Calculate complementary probabilities
            real_probability = 1.0 - fake_probability
            
            # Determine classification
            is_fake = fake_probability > 0.5
            confidence = fake_probability if is_fake else real_probability
            
            processing_time = time.time() - start_time
            
            return {
                "is_fake": bool(is_fake),
                "confidence": float(confidence),
                "fake_probability": float(fake_probability),
                "real_probability": float(real_probability),
                "model_type": self.model_type,
                "device": self.device,
                "processing_time": float(processing_time),
                "model_status": "loaded",
                "explanation": self._generate_explanation(fake_probability)
            }
            
        except Exception as e:
            logger.error(f"Fake profile detection failed: {e}")
            return {
                "error": str(e),
                "is_fake": False,
                "confidence": 0.0,
                "fake_probability": 0.0,
                "real_probability": 1.0,
                "model_status": "error"
            }
    
    def _generate_explanation(self, fake_probability: float) -> str:
        """Generate human-readable explanation of the detection result"""
        if fake_probability > 0.8:
            return "High confidence: Image shows strong indicators of being AI-generated or stock photo"
        elif fake_probability > 0.6:
            return "Moderate confidence: Image has some characteristics typical of generated/stock content"
        elif fake_probability > 0.4:
            return "Uncertain: Image has mixed characteristics, could be real or generated"
        elif fake_probability > 0.2:
            return "Likely real: Image shows characteristics typical of authentic photos"
        else:
            return "High confidence: Image appears to be an authentic, non-generated photograph"
    
    def batch_detect(self, images: list) -> list:
        """
        Process multiple images for fake detection
        
        Args:
            images: List of images (PIL Images, numpy arrays, or bytes)
            
        Returns:
            List of detection results
        """
        results = []
        for i, image in enumerate(images):
            try:
                result = self.detect_fake_profile(image)
                result['image_index'] = i
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to process image {i}: {e}")
                results.append({
                    "image_index": i,
                    "error": str(e),
                    "is_fake": False,
                    "confidence": 0.0,
                    "fake_probability": 0.0,
                    "real_probability": 1.0,
                    "model_status": "error"
                })
        
        return results

# Global detector instance
fake_profile_detector = None

def get_detector(model_type: str = "resnet50") -> FakeProfileDetector:
    """Get or create the global detector instance"""
    global fake_profile_detector
    if fake_profile_detector is None or fake_profile_detector.model_type != model_type:
        fake_profile_detector = FakeProfileDetector(model_type=model_type)
    return fake_profile_detector

def detect_fake_profile(image: Union[Image.Image, np.ndarray, bytes], 
                       model_type: str = "resnet50") -> Dict[str, Any]:
    """
    Convenience function for fake profile detection
    
    Args:
        image: Input image
        model_type: Type of model to use
        
    Returns:
        Detection results
    """
    detector = get_detector(model_type)
    return detector.detect_fake_profile(image)

# Example usage and testing
if __name__ == "__main__":
    # Test the detector
    detector = FakeProfileDetector(model_type="resnet50")
    
    # Create a test image
    test_image = Image.new('RGB', (224, 224), color='red')
    
    # Test detection
    result = detector.detect_fake_profile(test_image)
    print("Test Detection Result:")
    print(f"Is Fake: {result['is_fake']}")
    print(f"Confidence: {result['confidence']:.3f}")
    print(f"Fake Probability: {result['fake_probability']:.3f}")
    print(f"Real Probability: {result['real_probability']:.3f}")
    print(f"Explanation: {result['explanation']}")